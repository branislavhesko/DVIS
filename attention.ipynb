{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import einops\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, attention_store=None):\n",
    "        super().__init__()\n",
    "        self.queries_projection = nn.Linear(embed_size, embed_size)\n",
    "        self.values_projection = nn.Linear(embed_size, embed_size)\n",
    "        self.keys_projection = nn.Linear(embed_size, embed_size)\n",
    "        self.final_projection = nn.Linear(embed_size, embed_size)\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_store = attention_store\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 3\n",
    "        keys = self.keys_projection(x)\n",
    "        values = self.values_projection(x)\n",
    "        queries = self.queries_projection(x)\n",
    "        keys = einops.rearrange(keys, \"b n (h e) -> b n h e\", h=self.num_heads)\n",
    "        queries = einops.rearrange(queries, \"b n (h e) -> b n h e\", h=self.num_heads)\n",
    "        values = einops.rearrange(values, \"b n (h e) -> b n h e\", h=self.num_heads)\n",
    "        energy_term = torch.einsum(\"bqhe, bkhe -> bqhk\", queries, keys)\n",
    "        print(energy_term.shape)\n",
    "        divider = sqrt(self.embed_size)\n",
    "        mh_out = torch.softmax(energy_term, -1)\n",
    "        if self.attention_store is not None:\n",
    "            self.attention_store.append(mh_out.detach().cpu())\n",
    "        out = torch.einsum('bihv, bvhd -> bihd ', mh_out / divider, values)\n",
    "        out = einops.rearrange(out, \"b n h e -> b n (h e)\")\n",
    "        return self.final_projection(out)\n",
    "    \n",
    "x = torch.rand(4, 197, 768)\n",
    "MultiHeadAttention(768, 8)(x).shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4, 197, 8, 197])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 197, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadXCITAttention(torch.nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, attention_store=None):\n",
    "        super().__init__()\n",
    "        self.queries_projection = nn.Linear(embed_size, embed_size)\n",
    "        self.values_projection = nn.Linear(embed_size, embed_size)\n",
    "        self.keys_projection = nn.Linear(embed_size, embed_size)\n",
    "        self.final_projection = nn.Linear(embed_size, embed_size)\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_store = attention_store\n",
    "        self.tau = torch.nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 3\n",
    "        keys = self.keys_projection(x)\n",
    "        values = self.values_projection(x)\n",
    "        queries = self.queries_projection(x)\n",
    "        keys = einops.rearrange(keys, \"b n (h e) -> b n h e\", h=self.num_heads)\n",
    "        queries = einops.rearrange(queries, \"b n (h e) -> b n h e\", h=self.num_heads)\n",
    "        values = einops.rearrange(values, \"b n (h e) -> b n h e\", h=self.num_heads)\n",
    "        keys = F.normalize(keys, p=2, dim=1)\n",
    "        queries = F.normalize(queries, p=2, dim=1)\n",
    "        energy_term = torch.einsum(\"bnhe, bnhq -> behq\", queries, keys)\n",
    "        print(energy_term.shape)\n",
    "        divider = sqrt(self.embed_size)\n",
    "        mh_out = torch.softmax(energy_term, -1)\n",
    "        if self.attention_store is not None:\n",
    "            self.attention_store.append(mh_out.detach().cpu())\n",
    "        out = torch.einsum('behq, bnhe -> bnhq ', mh_out / divider, values)\n",
    "        print(out.shape)\n",
    "        out = einops.rearrange(out, \"b n h e -> b n (h e)\")\n",
    "        return self.final_projection(out)\n",
    "\n",
    "\n",
    "MultiHeadXCITAttention(768, 8)(x).shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4, 96, 8, 96])\n",
      "torch.Size([4, 197, 8, 96])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 197, 768])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from einops.layers.torch import Reduce, Rearrange\n",
    "\n",
    "class PatchEmbeddingPixelwise(torch.nn.Sequential):\n",
    "    \n",
    "    def __init__(self, stride, embedding_size, channels=3) -> None:\n",
    "        reduce = Reduce(\"b c (w i) (h k) -> b (c i k) w h\", \"mean\", i=stride, k=stride)\n",
    "        rearange = Rearrange(\"b e h w -> b (h w) e\")\n",
    "        linear = torch.nn.Linear(stride * stride * channels, embedding_size)\n",
    "        super().__init__(*[\n",
    "            reduce,\n",
    "            rearange,\n",
    "            linear\n",
    "        ])\n",
    "        \n",
    "imgs = torch.rand(4, 3, 512, 512)\n",
    "\n",
    "PatchEmbeddingPixelwise(4, 128)(imgs).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 16384, 128])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "x = einops.reduce(imgs, \"b c (w i) (h k) -> b (c i k) w h\", \"mean\", i=4, k=4)\n",
    "\n",
    "print(x[0, :, 0, 0])\n",
    "imgs[0, :, :4, :4]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.5891, 0.4272, 0.8274, 0.4417, 0.0085, 0.5833, 0.0616, 0.0424, 0.4950,\n",
      "        0.2065, 0.5875, 0.8506, 0.8575, 0.5328, 0.0374, 0.1130, 0.5295, 0.4659,\n",
      "        0.5719, 0.1116, 0.0251, 0.0025, 0.9558, 0.0884, 0.9224, 0.9056, 0.3549,\n",
      "        0.4874, 0.3215, 0.8398, 0.1643, 0.6919, 0.9742, 0.6123, 0.4258, 0.9993,\n",
      "        0.1846, 0.2410, 0.5798, 0.6895, 0.7292, 0.6438, 0.4387, 0.5016, 0.5945,\n",
      "        0.5443, 0.7958, 0.2468])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[0.5891, 0.4272, 0.8274, 0.4417],\n",
       "         [0.0085, 0.5833, 0.0616, 0.0424],\n",
       "         [0.4950, 0.2065, 0.5875, 0.8506],\n",
       "         [0.8575, 0.5328, 0.0374, 0.1130]],\n",
       "\n",
       "        [[0.5295, 0.4659, 0.5719, 0.1116],\n",
       "         [0.0251, 0.0025, 0.9558, 0.0884],\n",
       "         [0.9224, 0.9056, 0.3549, 0.4874],\n",
       "         [0.3215, 0.8398, 0.1643, 0.6919]],\n",
       "\n",
       "        [[0.9742, 0.6123, 0.4258, 0.9993],\n",
       "         [0.1846, 0.2410, 0.5798, 0.6895],\n",
       "         [0.7292, 0.6438, 0.4387, 0.5016],\n",
       "         [0.5945, 0.5443, 0.7958, 0.2468]]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "x = torch.rand(4, 8, 197, 96)\n",
    "x.transpose(-2, -1).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 96, 197])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80647bc31eee8f98a9857c024cb070ab8a251e4f0684aedce7063b7234f8932c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('rockstar': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}